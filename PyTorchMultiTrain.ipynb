{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a550f7fb-d2fe-4560-afe2-d75f90e2c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e78616-7497-4974-99d1-aaf25481723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd449d3-cc80-45d8-b37d-c934c5f5df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset that directly loads the file into memory and then retrieves data as needed\n",
    "# this helps deal with the file read bottlenecks, but the data has to be transformed and then loaded to the gpu\n",
    "class BowlingDataset(Dataset):\n",
    "    def __init__(self, fileName):\n",
    "        self.f = open(fileName, \"rb\")\n",
    "        self.length = int(os.stat(fileName).st_size/27)\n",
    "        #if self.length > 1500000:\n",
    "        #    self.length = 1500000\n",
    "        self.f.seek(0)\n",
    "        self.fileData = self.f.read()\n",
    "        self.f.close()\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gameData = self.fileData[idx * 27: idx * 27 + 27]\n",
    "        tempArray = []\n",
    "        for x in range(25):\n",
    "            tempArray += [v for v in format(gameData[x], \"08b\")]\n",
    "        finalScore = gameData[-1] * 256 + gameData[-2]\n",
    "        inputArray = [float(v) for v in tempArray][:120]\n",
    "        output = finalScore\n",
    "        return torch.tensor(inputArray[:]), torch.tensor(float(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160b508a-55fb-4a31-97ea-8219deab8d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(120, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.logits = self.relu_stack(x)\n",
    "        self.output = torch.nn.Sigmoid()(self.logits)\n",
    "        return self.output * 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c3fbc-7c63-40a9-a7af-af56dd5e2dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, modelList, loss_fn, optimizerList):\n",
    "    size = len(dataloader.dataset) # get number of samples\n",
    "    totalBatches = len(dataloader)\n",
    "    for model in modelList:\n",
    "        model.train() # need to look into what this exactly does\n",
    "    startTime = time.time()\n",
    "    for batchNum, (x, y) in enumerate(dataloader):\n",
    "        #grab model input and label as tensors on the gpu\n",
    "        xTensor = x.cuda()\n",
    "        yTensor = y.cuda()\n",
    "        \n",
    "        # zero out gradients of each optimizer\n",
    "        for optimizer in optimizerList:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # run though each model prediction + loss + backpropagation\n",
    "        \n",
    "        # prediction + loss on each model\n",
    "        for x in range(len(modelList)):\n",
    "            prediction = modelList[x](xTensor).squeeze(1)\n",
    "            loss = loss_fn(prediction, yTensor)\n",
    "        \n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if not batchNum % 1000:\n",
    "            print(f\"loss: {loss.item():.2f}\\tbatch num: {batchNum}/{totalBatches}\")\n",
    "            print(f\"took {time.time() - startTime} seconds\")\n",
    "            startTime = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
