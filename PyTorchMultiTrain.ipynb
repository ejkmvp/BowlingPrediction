{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a550f7fb-d2fe-4560-afe2-d75f90e2c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This runs a bit faster, but not a lot\n",
    "# it may just be best to load the whole model onto the gpu \n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e78616-7497-4974-99d1-aaf25481723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd449d3-cc80-45d8-b37d-c934c5f5df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset that directly loads the file into memory and then retrieves data as needed\n",
    "# this helps deal with the file read bottlenecks, but the data has to be transformed and then loaded to the gpu\n",
    "class BowlingDataset(Dataset):\n",
    "    def __init__(self, fileName):\n",
    "        self.f = open(fileName, \"rb\")\n",
    "        self.length = int(os.stat(fileName).st_size/27)\n",
    "        #if self.length > 1500000:\n",
    "        #    self.length = 1500000\n",
    "        self.f.seek(0)\n",
    "        self.fileData = self.f.read()\n",
    "        self.f.close()\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gameData = self.fileData[idx * 27: idx * 27 + 27]\n",
    "        tempArray = []\n",
    "        for x in range(25):\n",
    "            tempArray += [v for v in format(gameData[x], \"08b\")]\n",
    "        finalScore = gameData[-1] * 256 + gameData[-2]\n",
    "        inputArray = [float(v) for v in tempArray][:120]\n",
    "        output = finalScore\n",
    "        return torch.tensor(inputArray[:]), torch.tensor(float(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160b508a-55fb-4a31-97ea-8219deab8d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(120, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.logits = self.relu_stack(x)\n",
    "        self.output = torch.nn.Sigmoid()(self.logits)\n",
    "        return self.output * 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966c3fbc-7c63-40a9-a7af-af56dd5e2dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, modelList, lossFnList, optimizerList):\n",
    "    size = len(dataloader.dataset) # get number of samples\n",
    "    numModels = len(modelList)\n",
    "    totalBatches = len(dataloader)\n",
    "    predictionList = [0] * len(modelList)\n",
    "    lossList = [0] * len(modelList)\n",
    "    for model in modelList:\n",
    "        model.train() # need to look into what this exactly does\n",
    "    startTime = time.time()\n",
    "    for batchNum, (x, y) in enumerate(dataloader):\n",
    "        #grab model input and label as tensors on the gpu\n",
    "        xTensor = x.cuda()\n",
    "        yTensor = y.cuda()\n",
    "        \n",
    "        # the point of all these consecutive for loops is that the cuda operations should be async\n",
    "        # and then automatically synced up when the result tensor is needed\n",
    "        \n",
    "        # zero out gradients of each optimizer\n",
    "        for x in range(numModels):\n",
    "            optimizerList[x].zero_grad()\n",
    "            \n",
    "        # get predictions\n",
    "        for x in range(numModels):\n",
    "            predictionList[x] = modelList[x](xTensor)\n",
    "        \n",
    "        #compute losses\n",
    "        for x in range(numModels):\n",
    "            lossList[x] = lossFnList[x](predictionList[x].squeeze(1), yTensor)\n",
    "        \n",
    "        #run backprogagation\n",
    "        for x in range(numModels):\n",
    "            lossList[x].backward()\n",
    "        \n",
    "        #update weights\n",
    "        for x in range(numModels):\n",
    "            optimizerList[x].step()\n",
    "        \n",
    "        if not batchNum % 1000:\n",
    "            for x in range(numModels):\n",
    "                print(f\"Model{x} -- loss: {lossList[x].item():.2f}\\tbatch num: {batchNum}/{totalBatches}\")\n",
    "                print(f\"took {time.time() - startTime} seconds\")\n",
    "            startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "073b2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, modelList, loss_fn):\n",
    "    for model in modelList:\n",
    "        model.eval() # need to look into what this exactly does\n",
    "    size = len(dataloader.dataset)\n",
    "    numBatches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    total_losses = [0] * len(modelList)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            xTensor = x.cuda()\n",
    "            yTensor = y.cuda()\n",
    "            for x in range(len(modelList)):\n",
    "                pred = modelList[x](xTensor)\n",
    "                total_losses[x] += loss_fn(pred, yTensor).item()\n",
    "    for x in range(len(modelList)):\n",
    "        print(f\"model{x} Test Set -- Average Loss: {total_losses[x]/numBatches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d772f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMS\n",
    "batch_size = 128\n",
    "learning_rate = 0.0005\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ccf50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = BowlingDataset(\"ScoreDetailDataset.txt\")\n",
    "trainDataLoader = DataLoader(trainData, batch_size=batch_size, shuffle=True, pin_memory=True) #pin memory doesnt do shit bc the memory has to be grabbed from a physical file\n",
    "testData = BowlingDataset(\"ScoreDetailDatasetVSplit.txt\")\n",
    "testDataLoader = DataLoader(testData, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee9f567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Model0 -- loss: 3718.17\tbatch num: 0/31161\n",
      "took 1.0769994258880615 seconds\n",
      "Model1 -- loss: 4399.35\tbatch num: 0/31161\n",
      "took 1.0769994258880615 seconds\n",
      "Model2 -- loss: 4553.18\tbatch num: 0/31161\n",
      "took 1.0769994258880615 seconds\n",
      "Model3 -- loss: 4895.58\tbatch num: 0/31161\n",
      "took 1.0769994258880615 seconds\n",
      "Model0 -- loss: 262.78\tbatch num: 1000/31161\n",
      "took 17.823667287826538 seconds\n",
      "Model1 -- loss: 272.96\tbatch num: 1000/31161\n",
      "took 17.823667287826538 seconds\n",
      "Model2 -- loss: 312.71\tbatch num: 1000/31161\n",
      "took 17.823667287826538 seconds\n",
      "Model3 -- loss: 34057.62\tbatch num: 1000/31161\n",
      "took 17.823667287826538 seconds\n",
      "Model0 -- loss: 263.59\tbatch num: 2000/31161\n",
      "took 18.06487512588501 seconds\n",
      "Model1 -- loss: 266.79\tbatch num: 2000/31161\n",
      "took 18.06487512588501 seconds\n",
      "Model2 -- loss: 287.48\tbatch num: 2000/31161\n",
      "took 18.06487512588501 seconds\n",
      "Model3 -- loss: 35347.52\tbatch num: 2000/31161\n",
      "took 18.06487512588501 seconds\n",
      "Model0 -- loss: 261.91\tbatch num: 3000/31161\n",
      "took 17.99017357826233 seconds\n",
      "Model1 -- loss: 265.70\tbatch num: 3000/31161\n",
      "took 17.99017357826233 seconds\n",
      "Model2 -- loss: 271.01\tbatch num: 3000/31161\n",
      "took 17.99017357826233 seconds\n",
      "Model3 -- loss: 34196.46\tbatch num: 3000/31161\n",
      "took 17.991172552108765 seconds\n",
      "Model0 -- loss: 242.28\tbatch num: 4000/31161\n",
      "took 17.917306423187256 seconds\n",
      "Model1 -- loss: 257.82\tbatch num: 4000/31161\n",
      "took 17.917306423187256 seconds\n",
      "Model2 -- loss: 249.54\tbatch num: 4000/31161\n",
      "took 17.917306423187256 seconds\n",
      "Model3 -- loss: 33926.47\tbatch num: 4000/31161\n",
      "took 17.917306423187256 seconds\n",
      "Model0 -- loss: 222.38\tbatch num: 5000/31161\n",
      "took 18.017076015472412 seconds\n",
      "Model1 -- loss: 218.22\tbatch num: 5000/31161\n",
      "took 18.017076015472412 seconds\n",
      "Model2 -- loss: 247.80\tbatch num: 5000/31161\n",
      "took 18.017076015472412 seconds\n",
      "Model3 -- loss: 34508.38\tbatch num: 5000/31161\n",
      "took 18.017076015472412 seconds\n",
      "Model0 -- loss: 240.65\tbatch num: 6000/31161\n",
      "took 18.06216859817505 seconds\n",
      "Model1 -- loss: 245.56\tbatch num: 6000/31161\n",
      "took 18.06216859817505 seconds\n",
      "Model2 -- loss: 238.32\tbatch num: 6000/31161\n",
      "took 18.06316828727722 seconds\n",
      "Model3 -- loss: 33919.48\tbatch num: 6000/31161\n",
      "took 18.06316828727722 seconds\n",
      "Model0 -- loss: 200.50\tbatch num: 7000/31161\n",
      "took 17.970367431640625 seconds\n",
      "Model1 -- loss: 198.71\tbatch num: 7000/31161\n",
      "took 17.970367431640625 seconds\n",
      "Model2 -- loss: 204.22\tbatch num: 7000/31161\n",
      "took 17.970367431640625 seconds\n",
      "Model3 -- loss: 36337.50\tbatch num: 7000/31161\n",
      "took 17.970367431640625 seconds\n",
      "Model0 -- loss: 222.29\tbatch num: 8000/31161\n",
      "took 18.07243275642395 seconds\n",
      "Model1 -- loss: 220.71\tbatch num: 8000/31161\n",
      "took 18.07243275642395 seconds\n",
      "Model2 -- loss: 222.23\tbatch num: 8000/31161\n",
      "took 18.07243275642395 seconds\n",
      "Model3 -- loss: 32196.15\tbatch num: 8000/31161\n",
      "took 18.07243275642395 seconds\n",
      "Model0 -- loss: 123.08\tbatch num: 9000/31161\n",
      "took 18.047188997268677 seconds\n",
      "Model1 -- loss: 121.99\tbatch num: 9000/31161\n",
      "took 18.048194885253906 seconds\n",
      "Model2 -- loss: 126.53\tbatch num: 9000/31161\n",
      "took 18.048194885253906 seconds\n",
      "Model3 -- loss: 36107.91\tbatch num: 9000/31161\n",
      "took 18.048194885253906 seconds\n",
      "Model0 -- loss: 359.01\tbatch num: 10000/31161\n",
      "took 18.28373122215271 seconds\n",
      "Model1 -- loss: 377.68\tbatch num: 10000/31161\n",
      "took 18.28373122215271 seconds\n",
      "Model2 -- loss: 365.45\tbatch num: 10000/31161\n",
      "took 18.28373122215271 seconds\n",
      "Model3 -- loss: 30191.34\tbatch num: 10000/31161\n",
      "took 18.28373122215271 seconds\n",
      "Model0 -- loss: 292.45\tbatch num: 11000/31161\n",
      "took 18.039409637451172 seconds\n",
      "Model1 -- loss: 292.97\tbatch num: 11000/31161\n",
      "took 18.039409637451172 seconds\n",
      "Model2 -- loss: 294.05\tbatch num: 11000/31161\n",
      "took 18.039409637451172 seconds\n",
      "Model3 -- loss: 34207.47\tbatch num: 11000/31161\n",
      "took 18.039409637451172 seconds\n",
      "Model0 -- loss: 242.45\tbatch num: 12000/31161\n",
      "took 17.972076416015625 seconds\n",
      "Model1 -- loss: 242.97\tbatch num: 12000/31161\n",
      "took 17.972076416015625 seconds\n",
      "Model2 -- loss: 267.92\tbatch num: 12000/31161\n",
      "took 17.972076416015625 seconds\n",
      "Model3 -- loss: 35239.15\tbatch num: 12000/31161\n",
      "took 17.972076416015625 seconds\n",
      "Model0 -- loss: 158.93\tbatch num: 13000/31161\n",
      "took 18.02538537979126 seconds\n",
      "Model1 -- loss: 158.95\tbatch num: 13000/31161\n",
      "took 18.02538537979126 seconds\n",
      "Model2 -- loss: 168.07\tbatch num: 13000/31161\n",
      "took 18.02538537979126 seconds\n",
      "Model3 -- loss: 35689.59\tbatch num: 13000/31161\n",
      "took 18.02538537979126 seconds\n",
      "Model0 -- loss: 235.98\tbatch num: 14000/31161\n",
      "took 18.06521725654602 seconds\n",
      "Model1 -- loss: 241.13\tbatch num: 14000/31161\n",
      "took 18.06521725654602 seconds\n",
      "Model2 -- loss: 268.59\tbatch num: 14000/31161\n",
      "took 18.06521725654602 seconds\n",
      "Model3 -- loss: 34512.07\tbatch num: 14000/31161\n",
      "took 18.06521725654602 seconds\n",
      "Model0 -- loss: 216.06\tbatch num: 15000/31161\n",
      "took 18.04711675643921 seconds\n",
      "Model1 -- loss: 217.26\tbatch num: 15000/31161\n",
      "took 18.04711675643921 seconds\n",
      "Model2 -- loss: 225.13\tbatch num: 15000/31161\n",
      "took 18.048116207122803 seconds\n",
      "Model3 -- loss: 34733.14\tbatch num: 15000/31161\n",
      "took 18.048116207122803 seconds\n",
      "Model0 -- loss: 259.79\tbatch num: 16000/31161\n",
      "took 18.108378648757935 seconds\n",
      "Model1 -- loss: 262.41\tbatch num: 16000/31161\n",
      "took 18.108378648757935 seconds\n",
      "Model2 -- loss: 261.70\tbatch num: 16000/31161\n",
      "took 18.108378648757935 seconds\n",
      "Model3 -- loss: 36458.90\tbatch num: 16000/31161\n",
      "took 18.108378648757935 seconds\n",
      "Model0 -- loss: 189.34\tbatch num: 17000/31161\n",
      "took 17.996828079223633 seconds\n",
      "Model1 -- loss: 191.38\tbatch num: 17000/31161\n",
      "took 17.996828079223633 seconds\n",
      "Model2 -- loss: 191.73\tbatch num: 17000/31161\n",
      "took 17.996828079223633 seconds\n",
      "Model3 -- loss: 34310.50\tbatch num: 17000/31161\n",
      "took 17.996828079223633 seconds\n",
      "Model0 -- loss: 237.36\tbatch num: 18000/31161\n",
      "took 18.02839207649231 seconds\n",
      "Model1 -- loss: 242.61\tbatch num: 18000/31161\n",
      "took 18.02839207649231 seconds\n",
      "Model2 -- loss: 258.60\tbatch num: 18000/31161\n",
      "took 18.02839207649231 seconds\n",
      "Model3 -- loss: 33103.15\tbatch num: 18000/31161\n",
      "took 18.02839207649231 seconds\n",
      "Model0 -- loss: 317.65\tbatch num: 19000/31161\n",
      "took 17.93271231651306 seconds\n",
      "Model1 -- loss: 309.49\tbatch num: 19000/31161\n",
      "took 17.933714628219604 seconds\n",
      "Model2 -- loss: 312.36\tbatch num: 19000/31161\n",
      "took 17.933714628219604 seconds\n",
      "Model3 -- loss: 33009.16\tbatch num: 19000/31161\n",
      "took 17.933714628219604 seconds\n",
      "Model0 -- loss: 174.59\tbatch num: 20000/31161\n",
      "took 17.928165912628174 seconds\n",
      "Model1 -- loss: 187.82\tbatch num: 20000/31161\n",
      "took 17.928165912628174 seconds\n",
      "Model2 -- loss: 183.86\tbatch num: 20000/31161\n",
      "took 17.928165912628174 seconds\n",
      "Model3 -- loss: 37302.77\tbatch num: 20000/31161\n",
      "took 17.928165912628174 seconds\n",
      "Model0 -- loss: 156.48\tbatch num: 21000/31161\n",
      "took 17.92007350921631 seconds\n",
      "Model1 -- loss: 158.14\tbatch num: 21000/31161\n",
      "took 17.92107319831848 seconds\n",
      "Model2 -- loss: 159.01\tbatch num: 21000/31161\n",
      "took 17.92107319831848 seconds\n",
      "Model3 -- loss: 36189.98\tbatch num: 21000/31161\n",
      "took 17.92107319831848 seconds\n",
      "Model0 -- loss: 208.27\tbatch num: 22000/31161\n",
      "took 17.91548252105713 seconds\n",
      "Model1 -- loss: 210.43\tbatch num: 22000/31161\n",
      "took 17.91548252105713 seconds\n",
      "Model2 -- loss: 225.09\tbatch num: 22000/31161\n",
      "took 17.91548252105713 seconds\n",
      "Model3 -- loss: 31824.41\tbatch num: 22000/31161\n",
      "took 17.91548252105713 seconds\n",
      "Model0 -- loss: 192.23\tbatch num: 23000/31161\n",
      "took 17.92332172393799 seconds\n",
      "Model1 -- loss: 184.39\tbatch num: 23000/31161\n",
      "took 17.92332172393799 seconds\n",
      "Model2 -- loss: 192.71\tbatch num: 23000/31161\n",
      "took 17.92332172393799 seconds\n",
      "Model3 -- loss: 35095.52\tbatch num: 23000/31161\n",
      "took 17.92332172393799 seconds\n",
      "Model0 -- loss: 214.17\tbatch num: 24000/31161\n",
      "took 17.941757917404175 seconds\n",
      "Model1 -- loss: 217.33\tbatch num: 24000/31161\n",
      "took 17.942758083343506 seconds\n",
      "Model2 -- loss: 226.20\tbatch num: 24000/31161\n",
      "took 17.942758083343506 seconds\n",
      "Model3 -- loss: 32800.04\tbatch num: 24000/31161\n",
      "took 17.942758083343506 seconds\n",
      "Model0 -- loss: 219.76\tbatch num: 25000/31161\n",
      "took 17.92867088317871 seconds\n",
      "Model1 -- loss: 210.41\tbatch num: 25000/31161\n",
      "took 17.92867088317871 seconds\n",
      "Model2 -- loss: 216.16\tbatch num: 25000/31161\n",
      "took 17.92867088317871 seconds\n",
      "Model3 -- loss: 35196.76\tbatch num: 25000/31161\n",
      "took 17.92867088317871 seconds\n",
      "Model0 -- loss: 284.05\tbatch num: 26000/31161\n",
      "took 17.927879095077515 seconds\n",
      "Model1 -- loss: 286.41\tbatch num: 26000/31161\n",
      "took 17.927879095077515 seconds\n",
      "Model2 -- loss: 287.69\tbatch num: 26000/31161\n",
      "took 17.92888069152832 seconds\n",
      "Model3 -- loss: 35329.66\tbatch num: 26000/31161\n",
      "took 17.92888069152832 seconds\n",
      "Model0 -- loss: 177.71\tbatch num: 27000/31161\n",
      "took 17.92175555229187 seconds\n",
      "Model1 -- loss: 181.27\tbatch num: 27000/31161\n",
      "took 17.92175555229187 seconds\n",
      "Model2 -- loss: 188.03\tbatch num: 27000/31161\n",
      "took 17.92175555229187 seconds\n",
      "Model3 -- loss: 37804.67\tbatch num: 27000/31161\n",
      "took 17.92175555229187 seconds\n",
      "Model0 -- loss: 208.34\tbatch num: 28000/31161\n",
      "took 18.26930022239685 seconds\n",
      "Model1 -- loss: 205.50\tbatch num: 28000/31161\n",
      "took 18.26930022239685 seconds\n",
      "Model2 -- loss: 214.84\tbatch num: 28000/31161\n",
      "took 18.26930022239685 seconds\n",
      "Model3 -- loss: 34467.55\tbatch num: 28000/31161\n",
      "took 18.26930022239685 seconds\n",
      "Model0 -- loss: 229.50\tbatch num: 29000/31161\n",
      "took 18.772746086120605 seconds\n",
      "Model1 -- loss: 229.02\tbatch num: 29000/31161\n",
      "took 18.772746086120605 seconds\n",
      "Model2 -- loss: 247.47\tbatch num: 29000/31161\n",
      "took 18.773744583129883 seconds\n",
      "Model3 -- loss: 35450.35\tbatch num: 29000/31161\n",
      "took 18.773744583129883 seconds\n",
      "Model0 -- loss: 241.59\tbatch num: 30000/31161\n",
      "took 19.394150733947754 seconds\n",
      "Model1 -- loss: 238.21\tbatch num: 30000/31161\n",
      "took 19.394150733947754 seconds\n",
      "Model2 -- loss: 253.38\tbatch num: 30000/31161\n",
      "took 19.394150733947754 seconds\n",
      "Model3 -- loss: 35314.60\tbatch num: 30000/31161\n",
      "took 19.394150733947754 seconds\n",
      "Model0 -- loss: 190.80\tbatch num: 31000/31161\n",
      "took 18.16736912727356 seconds\n",
      "Model1 -- loss: 196.43\tbatch num: 31000/31161\n",
      "took 18.16736912727356 seconds\n",
      "Model2 -- loss: 199.98\tbatch num: 31000/31161\n",
      "took 18.16736912727356 seconds\n",
      "Model3 -- loss: 33332.67\tbatch num: 31000/31161\n",
      "took 18.16736912727356 seconds\n",
      "Epoch 0 took 564.6846418380737 seconds\n",
      "model0 Test Set -- Average Loss: 35028.8056640625\n",
      "model1 Test Set -- Average Loss: 35028.8056640625\n",
      "model2 Test Set -- Average Loss: 35028.8056640625\n",
      "model3 Test Set -- Average Loss: 35028.8056640625\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "X:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([104])) that is different to the input size (torch.Size([104, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model0 -- loss: 206.20\tbatch num: 0/31161\n",
      "took 0.2199997901916504 seconds\n",
      "Model1 -- loss: 209.61\tbatch num: 0/31161\n",
      "took 0.22100067138671875 seconds\n",
      "Model2 -- loss: 219.51\tbatch num: 0/31161\n",
      "took 0.2219984531402588 seconds\n",
      "Model3 -- loss: 38518.09\tbatch num: 0/31161\n",
      "took 0.2219984531402588 seconds\n",
      "Model0 -- loss: 190.32\tbatch num: 1000/31161\n",
      "took 19.88113307952881 seconds\n",
      "Model1 -- loss: 192.96\tbatch num: 1000/31161\n",
      "took 19.88113307952881 seconds\n",
      "Model2 -- loss: 194.19\tbatch num: 1000/31161\n",
      "took 19.882134675979614 seconds\n",
      "Model3 -- loss: 37706.70\tbatch num: 1000/31161\n",
      "took 19.882134675979614 seconds\n",
      "Model0 -- loss: 190.50\tbatch num: 2000/31161\n",
      "took 18.92127227783203 seconds\n",
      "Model1 -- loss: 189.33\tbatch num: 2000/31161\n",
      "took 18.92127227783203 seconds\n",
      "Model2 -- loss: 189.42\tbatch num: 2000/31161\n",
      "took 18.92127227783203 seconds\n",
      "Model3 -- loss: 35705.48\tbatch num: 2000/31161\n",
      "took 18.92127227783203 seconds\n",
      "Model0 -- loss: 210.39\tbatch num: 3000/31161\n",
      "took 18.765220165252686 seconds\n",
      "Model1 -- loss: 219.06\tbatch num: 3000/31161\n",
      "took 18.765220165252686 seconds\n",
      "Model2 -- loss: 227.19\tbatch num: 3000/31161\n",
      "took 18.765220165252686 seconds\n",
      "Model3 -- loss: 36433.25\tbatch num: 3000/31161\n",
      "took 18.765220165252686 seconds\n",
      "Model0 -- loss: 254.36\tbatch num: 4000/31161\n",
      "took 18.186519145965576 seconds\n",
      "Model1 -- loss: 256.24\tbatch num: 4000/31161\n",
      "took 18.187519073486328 seconds\n",
      "Model2 -- loss: 264.34\tbatch num: 4000/31161\n",
      "took 18.187519073486328 seconds\n",
      "Model3 -- loss: 38081.32\tbatch num: 4000/31161\n",
      "took 18.187519073486328 seconds\n",
      "Model0 -- loss: 271.27\tbatch num: 5000/31161\n",
      "took 18.741466522216797 seconds\n",
      "Model1 -- loss: 271.22\tbatch num: 5000/31161\n",
      "took 18.741466522216797 seconds\n",
      "Model2 -- loss: 275.23\tbatch num: 5000/31161\n",
      "took 18.742462873458862 seconds\n",
      "Model3 -- loss: 32948.17\tbatch num: 5000/31161\n",
      "took 18.74346160888672 seconds\n",
      "Model0 -- loss: 234.30\tbatch num: 6000/31161\n",
      "took 18.11033034324646 seconds\n",
      "Model1 -- loss: 227.05\tbatch num: 6000/31161\n",
      "took 18.11033034324646 seconds\n",
      "Model2 -- loss: 229.76\tbatch num: 6000/31161\n",
      "took 18.11033034324646 seconds\n",
      "Model3 -- loss: 35142.93\tbatch num: 6000/31161\n",
      "took 18.11033034324646 seconds\n",
      "Model0 -- loss: 232.99\tbatch num: 7000/31161\n",
      "took 18.09180521965027 seconds\n",
      "Model1 -- loss: 240.13\tbatch num: 7000/31161\n",
      "took 18.09180521965027 seconds\n",
      "Model2 -- loss: 246.96\tbatch num: 7000/31161\n",
      "took 18.09180521965027 seconds\n",
      "Model3 -- loss: 36088.12\tbatch num: 7000/31161\n",
      "took 18.09180521965027 seconds\n",
      "Model0 -- loss: 193.19\tbatch num: 8000/31161\n",
      "took 17.990801334381104 seconds\n",
      "Model1 -- loss: 191.36\tbatch num: 8000/31161\n",
      "took 17.990801334381104 seconds\n",
      "Model2 -- loss: 188.42\tbatch num: 8000/31161\n",
      "took 17.991801500320435 seconds\n",
      "Model3 -- loss: 36184.89\tbatch num: 8000/31161\n",
      "took 17.991801500320435 seconds\n",
      "Model0 -- loss: 184.17\tbatch num: 9000/31161\n",
      "took 18.089961767196655 seconds\n",
      "Model1 -- loss: 184.47\tbatch num: 9000/31161\n",
      "took 18.089961767196655 seconds\n",
      "Model2 -- loss: 191.53\tbatch num: 9000/31161\n",
      "took 18.089961767196655 seconds\n",
      "Model3 -- loss: 35835.38\tbatch num: 9000/31161\n",
      "took 18.090963125228882 seconds\n",
      "Model0 -- loss: 247.66\tbatch num: 10000/31161\n",
      "took 18.10908818244934 seconds\n",
      "Model1 -- loss: 252.70\tbatch num: 10000/31161\n",
      "took 18.10908818244934 seconds\n",
      "Model2 -- loss: 247.28\tbatch num: 10000/31161\n",
      "took 18.10908818244934 seconds\n",
      "Model3 -- loss: 34566.97\tbatch num: 10000/31161\n",
      "took 18.10908818244934 seconds\n",
      "Model0 -- loss: 265.88\tbatch num: 11000/31161\n",
      "took 17.992077350616455 seconds\n",
      "Model1 -- loss: 257.72\tbatch num: 11000/31161\n",
      "took 17.99307608604431 seconds\n",
      "Model2 -- loss: 260.55\tbatch num: 11000/31161\n",
      "took 17.99307608604431 seconds\n",
      "Model3 -- loss: 35243.50\tbatch num: 11000/31161\n",
      "took 17.99307608604431 seconds\n",
      "Model0 -- loss: 173.74\tbatch num: 12000/31161\n",
      "took 17.923540353775024 seconds\n",
      "Model1 -- loss: 178.97\tbatch num: 12000/31161\n",
      "took 17.923540353775024 seconds\n",
      "Model2 -- loss: 170.21\tbatch num: 12000/31161\n",
      "took 17.923540353775024 seconds\n",
      "Model3 -- loss: 35424.70\tbatch num: 12000/31161\n",
      "took 17.923540353775024 seconds\n",
      "Model0 -- loss: 238.54\tbatch num: 13000/31161\n",
      "took 17.853758573532104 seconds\n",
      "Model1 -- loss: 240.00\tbatch num: 13000/31161\n",
      "took 17.853758573532104 seconds\n",
      "Model2 -- loss: 239.31\tbatch num: 13000/31161\n",
      "took 17.853758573532104 seconds\n",
      "Model3 -- loss: 35607.00\tbatch num: 13000/31161\n",
      "took 17.853758573532104 seconds\n",
      "Model0 -- loss: 242.17\tbatch num: 14000/31161\n",
      "took 17.94188690185547 seconds\n",
      "Model1 -- loss: 239.80\tbatch num: 14000/31161\n",
      "took 17.94188690185547 seconds\n",
      "Model2 -- loss: 239.27\tbatch num: 14000/31161\n",
      "took 17.94188690185547 seconds\n",
      "Model3 -- loss: 35306.66\tbatch num: 14000/31161\n",
      "took 17.94188690185547 seconds\n",
      "Model0 -- loss: 193.76\tbatch num: 15000/31161\n",
      "took 17.90802812576294 seconds\n",
      "Model1 -- loss: 192.07\tbatch num: 15000/31161\n",
      "took 17.90802812576294 seconds\n",
      "Model2 -- loss: 198.85\tbatch num: 15000/31161\n",
      "took 17.90802812576294 seconds\n",
      "Model3 -- loss: 38183.41\tbatch num: 15000/31161\n",
      "took 17.90802812576294 seconds\n",
      "Model0 -- loss: 240.09\tbatch num: 16000/31161\n",
      "took 18.754342079162598 seconds\n",
      "Model1 -- loss: 233.28\tbatch num: 16000/31161\n",
      "took 18.754342079162598 seconds\n",
      "Model2 -- loss: 235.47\tbatch num: 16000/31161\n",
      "took 18.754342079162598 seconds\n",
      "Model3 -- loss: 36261.85\tbatch num: 16000/31161\n",
      "took 18.754342079162598 seconds\n",
      "Model0 -- loss: 188.45\tbatch num: 17000/31161\n",
      "took 18.564507246017456 seconds\n",
      "Model1 -- loss: 190.62\tbatch num: 17000/31161\n",
      "took 18.564507246017456 seconds\n",
      "Model2 -- loss: 197.71\tbatch num: 17000/31161\n",
      "took 18.564507246017456 seconds\n",
      "Model3 -- loss: 35674.96\tbatch num: 17000/31161\n",
      "took 18.564507246017456 seconds\n",
      "Model0 -- loss: 207.48\tbatch num: 18000/31161\n",
      "took 18.821001529693604 seconds\n",
      "Model1 -- loss: 210.53\tbatch num: 18000/31161\n",
      "took 18.821001529693604 seconds\n",
      "Model2 -- loss: 213.04\tbatch num: 18000/31161\n",
      "took 18.821001529693604 seconds\n",
      "Model3 -- loss: 34401.53\tbatch num: 18000/31161\n",
      "took 18.821001529693604 seconds\n",
      "Model0 -- loss: 205.35\tbatch num: 19000/31161\n",
      "took 18.62902569770813 seconds\n",
      "Model1 -- loss: 200.47\tbatch num: 19000/31161\n",
      "took 18.62902569770813 seconds\n",
      "Model2 -- loss: 206.28\tbatch num: 19000/31161\n",
      "took 18.62902569770813 seconds\n",
      "Model3 -- loss: 34829.18\tbatch num: 19000/31161\n",
      "took 18.630024909973145 seconds\n",
      "Model0 -- loss: 196.46\tbatch num: 20000/31161\n",
      "took 18.655001401901245 seconds\n",
      "Model1 -- loss: 201.27\tbatch num: 20000/31161\n",
      "took 18.655001401901245 seconds\n",
      "Model2 -- loss: 203.55\tbatch num: 20000/31161\n",
      "took 18.655001401901245 seconds\n",
      "Model3 -- loss: 37082.81\tbatch num: 20000/31161\n",
      "took 18.655001401901245 seconds\n",
      "Model0 -- loss: 208.07\tbatch num: 21000/31161\n",
      "took 18.669999599456787 seconds\n",
      "Model1 -- loss: 206.74\tbatch num: 21000/31161\n",
      "took 18.669999599456787 seconds\n",
      "Model2 -- loss: 201.12\tbatch num: 21000/31161\n",
      "took 18.67099905014038 seconds\n",
      "Model3 -- loss: 33272.87\tbatch num: 21000/31161\n",
      "took 18.67099905014038 seconds\n",
      "Model0 -- loss: 211.85\tbatch num: 22000/31161\n",
      "took 18.892964601516724 seconds\n",
      "Model1 -- loss: 208.25\tbatch num: 22000/31161\n",
      "took 18.892964601516724 seconds\n",
      "Model2 -- loss: 215.36\tbatch num: 22000/31161\n",
      "took 18.892964601516724 seconds\n",
      "Model3 -- loss: 36794.35\tbatch num: 22000/31161\n",
      "took 18.892964601516724 seconds\n",
      "Model0 -- loss: 269.14\tbatch num: 23000/31161\n",
      "took 18.09023952484131 seconds\n",
      "Model1 -- loss: 273.07\tbatch num: 23000/31161\n",
      "took 18.09023952484131 seconds\n",
      "Model2 -- loss: 263.87\tbatch num: 23000/31161\n",
      "took 18.091240167617798 seconds\n",
      "Model3 -- loss: 34171.72\tbatch num: 23000/31161\n",
      "took 18.091240167617798 seconds\n",
      "Model0 -- loss: 229.19\tbatch num: 24000/31161\n",
      "took 19.079607248306274 seconds\n",
      "Model1 -- loss: 225.73\tbatch num: 24000/31161\n",
      "took 19.080607652664185 seconds\n",
      "Model2 -- loss: 233.43\tbatch num: 24000/31161\n",
      "took 19.080607652664185 seconds\n",
      "Model3 -- loss: 33309.94\tbatch num: 24000/31161\n",
      "took 19.080607652664185 seconds\n",
      "Model0 -- loss: 204.00\tbatch num: 25000/31161\n",
      "took 19.054999828338623 seconds\n",
      "Model1 -- loss: 203.00\tbatch num: 25000/31161\n",
      "took 19.054999828338623 seconds\n",
      "Model2 -- loss: 212.22\tbatch num: 25000/31161\n",
      "took 19.054999828338623 seconds\n",
      "Model3 -- loss: 35902.08\tbatch num: 25000/31161\n",
      "took 19.054999828338623 seconds\n",
      "Model0 -- loss: 181.34\tbatch num: 26000/31161\n",
      "took 19.404999017715454 seconds\n",
      "Model1 -- loss: 178.06\tbatch num: 26000/31161\n",
      "took 19.404999017715454 seconds\n",
      "Model2 -- loss: 179.55\tbatch num: 26000/31161\n",
      "took 19.404999017715454 seconds\n",
      "Model3 -- loss: 34721.27\tbatch num: 26000/31161\n",
      "took 19.404999017715454 seconds\n",
      "Model0 -- loss: 157.12\tbatch num: 27000/31161\n",
      "took 19.077003002166748 seconds\n",
      "Model1 -- loss: 154.55\tbatch num: 27000/31161\n",
      "took 19.077003002166748 seconds\n",
      "Model2 -- loss: 155.94\tbatch num: 27000/31161\n",
      "took 19.077003002166748 seconds\n",
      "Model3 -- loss: 35959.07\tbatch num: 27000/31161\n",
      "took 19.078001022338867 seconds\n",
      "Model0 -- loss: 174.87\tbatch num: 28000/31161\n",
      "took 19.09100079536438 seconds\n",
      "Model1 -- loss: 178.36\tbatch num: 28000/31161\n",
      "took 19.09100079536438 seconds\n",
      "Model2 -- loss: 177.38\tbatch num: 28000/31161\n",
      "took 19.09100079536438 seconds\n",
      "Model3 -- loss: 34317.67\tbatch num: 28000/31161\n",
      "took 19.09100079536438 seconds\n",
      "Model0 -- loss: 193.23\tbatch num: 29000/31161\n",
      "took 19.891998291015625 seconds\n",
      "Model1 -- loss: 190.31\tbatch num: 29000/31161\n",
      "took 19.891998291015625 seconds\n",
      "Model2 -- loss: 200.89\tbatch num: 29000/31161\n",
      "took 19.891998291015625 seconds\n",
      "Model3 -- loss: 36094.63\tbatch num: 29000/31161\n",
      "took 19.891998291015625 seconds\n",
      "Model0 -- loss: 218.54\tbatch num: 30000/31161\n",
      "took 19.157113313674927 seconds\n",
      "Model1 -- loss: 214.01\tbatch num: 30000/31161\n",
      "took 19.157113313674927 seconds\n",
      "Model2 -- loss: 211.57\tbatch num: 30000/31161\n",
      "took 19.157113313674927 seconds\n",
      "Model3 -- loss: 37046.43\tbatch num: 30000/31161\n",
      "took 19.157113313674927 seconds\n",
      "Model0 -- loss: 223.79\tbatch num: 31000/31161\n",
      "took 19.132876873016357 seconds\n",
      "Model1 -- loss: 219.44\tbatch num: 31000/31161\n",
      "took 19.132876873016357 seconds\n",
      "Model2 -- loss: 222.10\tbatch num: 31000/31161\n",
      "took 19.132876873016357 seconds\n",
      "Model3 -- loss: 36931.21\tbatch num: 31000/31161\n",
      "took 19.132876873016357 seconds\n",
      "Epoch 1 took 581.0105648040771 seconds\n",
      "model0 Test Set -- Average Loss: 35005.706298828125\n",
      "model1 Test Set -- Average Loss: 35005.706298828125\n",
      "model2 Test Set -- Average Loss: 35005.706298828125\n",
      "model3 Test Set -- Average Loss: 35005.706298828125\n",
      "Starting epoch 2\n",
      "Model0 -- loss: 229.24\tbatch num: 0/31161\n",
      "took 0.256000280380249 seconds\n",
      "Model1 -- loss: 228.83\tbatch num: 0/31161\n",
      "took 0.256000280380249 seconds\n",
      "Model2 -- loss: 228.18\tbatch num: 0/31161\n",
      "took 0.256000280380249 seconds\n",
      "Model3 -- loss: 35981.34\tbatch num: 0/31161\n",
      "took 0.257000207901001 seconds\n",
      "Model0 -- loss: 186.63\tbatch num: 1000/31161\n",
      "took 19.134999752044678 seconds\n",
      "Model1 -- loss: 184.76\tbatch num: 1000/31161\n",
      "took 19.134999752044678 seconds\n",
      "Model2 -- loss: 185.31\tbatch num: 1000/31161\n",
      "took 19.134999752044678 seconds\n",
      "Model3 -- loss: 32641.48\tbatch num: 1000/31161\n",
      "took 19.134999752044678 seconds\n",
      "Model0 -- loss: 230.79\tbatch num: 2000/31161\n",
      "took 19.498900890350342 seconds\n",
      "Model1 -- loss: 227.92\tbatch num: 2000/31161\n",
      "took 19.498900890350342 seconds\n",
      "Model2 -- loss: 234.14\tbatch num: 2000/31161\n",
      "took 19.49989891052246 seconds\n",
      "Model3 -- loss: 34349.12\tbatch num: 2000/31161\n",
      "took 19.49989891052246 seconds\n",
      "Model0 -- loss: 222.50\tbatch num: 3000/31161\n",
      "took 19.841668605804443 seconds\n",
      "Model1 -- loss: 220.90\tbatch num: 3000/31161\n",
      "took 19.842668533325195 seconds\n",
      "Model2 -- loss: 219.28\tbatch num: 3000/31161\n",
      "took 19.842668533325195 seconds\n",
      "Model3 -- loss: 33243.24\tbatch num: 3000/31161\n",
      "took 19.842668533325195 seconds\n",
      "Model0 -- loss: 177.82\tbatch num: 4000/31161\n",
      "took 18.60284924507141 seconds\n",
      "Model1 -- loss: 180.02\tbatch num: 4000/31161\n",
      "took 18.60284924507141 seconds\n",
      "Model2 -- loss: 180.79\tbatch num: 4000/31161\n",
      "took 18.60284924507141 seconds\n",
      "Model3 -- loss: 35489.81\tbatch num: 4000/31161\n",
      "took 18.60284924507141 seconds\n",
      "Model0 -- loss: 214.33\tbatch num: 5000/31161\n",
      "took 19.199597597122192 seconds\n",
      "Model1 -- loss: 221.42\tbatch num: 5000/31161\n",
      "took 19.199597597122192 seconds\n",
      "Model2 -- loss: 216.41\tbatch num: 5000/31161\n",
      "took 19.199597597122192 seconds\n",
      "Model3 -- loss: 35546.45\tbatch num: 5000/31161\n",
      "took 19.199597597122192 seconds\n",
      "Model0 -- loss: 189.69\tbatch num: 6000/31161\n",
      "took 19.386003017425537 seconds\n",
      "Model1 -- loss: 190.09\tbatch num: 6000/31161\n",
      "took 19.386003017425537 seconds\n",
      "Model2 -- loss: 186.62\tbatch num: 6000/31161\n",
      "took 19.386003017425537 seconds\n",
      "Model3 -- loss: 31704.96\tbatch num: 6000/31161\n",
      "took 19.38700008392334 seconds\n",
      "Model0 -- loss: 185.22\tbatch num: 7000/31161\n",
      "took 19.242884874343872 seconds\n",
      "Model1 -- loss: 183.65\tbatch num: 7000/31161\n",
      "took 19.242884874343872 seconds\n",
      "Model2 -- loss: 180.34\tbatch num: 7000/31161\n",
      "took 19.243884325027466 seconds\n",
      "Model3 -- loss: 34535.77\tbatch num: 7000/31161\n",
      "took 19.243884325027466 seconds\n",
      "Model0 -- loss: 192.64\tbatch num: 8000/31161\n",
      "took 19.42778515815735 seconds\n",
      "Model1 -- loss: 190.94\tbatch num: 8000/31161\n",
      "took 19.42778515815735 seconds\n",
      "Model2 -- loss: 188.43\tbatch num: 8000/31161\n",
      "took 19.42778515815735 seconds\n",
      "Model3 -- loss: 36767.60\tbatch num: 8000/31161\n",
      "took 19.42778515815735 seconds\n",
      "Model0 -- loss: 198.48\tbatch num: 9000/31161\n",
      "took 20.54869318008423 seconds\n",
      "Model1 -- loss: 198.67\tbatch num: 9000/31161\n",
      "took 20.54869318008423 seconds\n",
      "Model2 -- loss: 197.00\tbatch num: 9000/31161\n",
      "took 20.549689054489136 seconds\n",
      "Model3 -- loss: 37661.84\tbatch num: 9000/31161\n",
      "took 20.549689054489136 seconds\n",
      "Model0 -- loss: 239.95\tbatch num: 10000/31161\n",
      "took 19.59180474281311 seconds\n",
      "Model1 -- loss: 237.00\tbatch num: 10000/31161\n",
      "took 19.59180474281311 seconds\n",
      "Model2 -- loss: 243.19\tbatch num: 10000/31161\n",
      "took 19.59180474281311 seconds\n",
      "Model3 -- loss: 33854.59\tbatch num: 10000/31161\n",
      "took 19.59180474281311 seconds\n",
      "Model0 -- loss: 294.06\tbatch num: 11000/31161\n",
      "took 18.332913875579834 seconds\n",
      "Model1 -- loss: 292.62\tbatch num: 11000/31161\n",
      "took 18.332913875579834 seconds\n",
      "Model2 -- loss: 295.48\tbatch num: 11000/31161\n",
      "took 18.332913875579834 seconds\n",
      "Model3 -- loss: 33032.16\tbatch num: 11000/31161\n",
      "took 18.33391284942627 seconds\n",
      "Model0 -- loss: 255.88\tbatch num: 12000/31161\n",
      "took 19.48340153694153 seconds\n",
      "Model1 -- loss: 250.76\tbatch num: 12000/31161\n",
      "took 19.48340153694153 seconds\n",
      "Model2 -- loss: 253.13\tbatch num: 12000/31161\n",
      "took 19.48340153694153 seconds\n",
      "Model3 -- loss: 34094.22\tbatch num: 12000/31161\n",
      "took 19.48340153694153 seconds\n",
      "Model0 -- loss: 218.26\tbatch num: 13000/31161\n",
      "took 18.241231441497803 seconds\n",
      "Model1 -- loss: 224.00\tbatch num: 13000/31161\n",
      "took 18.241231441497803 seconds\n",
      "Model2 -- loss: 229.92\tbatch num: 13000/31161\n",
      "took 18.241231441497803 seconds\n",
      "Model3 -- loss: 35047.13\tbatch num: 13000/31161\n",
      "took 18.241231441497803 seconds\n",
      "Model0 -- loss: 195.59\tbatch num: 14000/31161\n",
      "took 18.186819553375244 seconds\n",
      "Model1 -- loss: 192.37\tbatch num: 14000/31161\n",
      "took 18.186819553375244 seconds\n",
      "Model2 -- loss: 191.61\tbatch num: 14000/31161\n",
      "took 18.186819553375244 seconds\n",
      "Model3 -- loss: 34732.58\tbatch num: 14000/31161\n",
      "took 18.186819553375244 seconds\n",
      "Model0 -- loss: 201.14\tbatch num: 15000/31161\n",
      "took 19.321666717529297 seconds\n",
      "Model1 -- loss: 197.72\tbatch num: 15000/31161\n",
      "took 19.321666717529297 seconds\n",
      "Model2 -- loss: 197.19\tbatch num: 15000/31161\n",
      "took 19.321666717529297 seconds\n",
      "Model3 -- loss: 36854.09\tbatch num: 15000/31161\n",
      "took 19.321666717529297 seconds\n",
      "Model0 -- loss: 260.61\tbatch num: 16000/31161\n",
      "took 19.361145734786987 seconds\n",
      "Model1 -- loss: 261.51\tbatch num: 16000/31161\n",
      "took 19.361145734786987 seconds\n",
      "Model2 -- loss: 262.89\tbatch num: 16000/31161\n",
      "took 19.361145734786987 seconds\n",
      "Model3 -- loss: 34389.01\tbatch num: 16000/31161\n",
      "took 19.361145734786987 seconds\n",
      "Model0 -- loss: 207.32\tbatch num: 17000/31161\n",
      "took 19.41803479194641 seconds\n",
      "Model1 -- loss: 213.37\tbatch num: 17000/31161\n",
      "took 19.41803479194641 seconds\n",
      "Model2 -- loss: 218.48\tbatch num: 17000/31161\n",
      "took 19.41803479194641 seconds\n",
      "Model3 -- loss: 35851.22\tbatch num: 17000/31161\n",
      "took 19.41803479194641 seconds\n",
      "Model0 -- loss: 214.83\tbatch num: 18000/31161\n",
      "took 18.273198127746582 seconds\n",
      "Model1 -- loss: 214.32\tbatch num: 18000/31161\n",
      "took 18.273198127746582 seconds\n",
      "Model2 -- loss: 221.44\tbatch num: 18000/31161\n",
      "took 18.274197816848755 seconds\n",
      "Model3 -- loss: 35782.25\tbatch num: 18000/31161\n",
      "took 18.274197816848755 seconds\n",
      "Model0 -- loss: 176.35\tbatch num: 19000/31161\n",
      "took 18.13907766342163 seconds\n",
      "Model1 -- loss: 173.81\tbatch num: 19000/31161\n",
      "took 18.13907766342163 seconds\n",
      "Model2 -- loss: 188.29\tbatch num: 19000/31161\n",
      "took 18.13907766342163 seconds\n",
      "Model3 -- loss: 33506.85\tbatch num: 19000/31161\n",
      "took 18.13907766342163 seconds\n",
      "Model0 -- loss: 170.02\tbatch num: 20000/31161\n",
      "took 18.106307983398438 seconds\n",
      "Model1 -- loss: 168.35\tbatch num: 20000/31161\n",
      "took 18.106307983398438 seconds\n",
      "Model2 -- loss: 168.48\tbatch num: 20000/31161\n",
      "took 18.106307983398438 seconds\n",
      "Model3 -- loss: 38906.76\tbatch num: 20000/31161\n",
      "took 18.106307983398438 seconds\n",
      "Model0 -- loss: 166.10\tbatch num: 21000/31161\n",
      "took 17.944600105285645 seconds\n",
      "Model1 -- loss: 167.72\tbatch num: 21000/31161\n",
      "took 17.944600105285645 seconds\n",
      "Model2 -- loss: 164.59\tbatch num: 21000/31161\n",
      "took 17.944600105285645 seconds\n",
      "Model3 -- loss: 34349.98\tbatch num: 21000/31161\n",
      "took 17.944600105285645 seconds\n",
      "Model0 -- loss: 161.36\tbatch num: 22000/31161\n",
      "took 17.940993785858154 seconds\n",
      "Model1 -- loss: 164.18\tbatch num: 22000/31161\n",
      "took 17.9419949054718 seconds\n",
      "Model2 -- loss: 170.78\tbatch num: 22000/31161\n",
      "took 17.9419949054718 seconds\n",
      "Model3 -- loss: 32793.43\tbatch num: 22000/31161\n",
      "took 17.9419949054718 seconds\n",
      "Model0 -- loss: 207.81\tbatch num: 23000/31161\n",
      "took 17.97268557548523 seconds\n",
      "Model1 -- loss: 215.60\tbatch num: 23000/31161\n",
      "took 17.97268557548523 seconds\n",
      "Model2 -- loss: 216.88\tbatch num: 23000/31161\n",
      "took 17.97268557548523 seconds\n",
      "Model3 -- loss: 33019.13\tbatch num: 23000/31161\n",
      "took 17.97268557548523 seconds\n",
      "Model0 -- loss: 200.66\tbatch num: 24000/31161\n",
      "took 17.861862421035767 seconds\n",
      "Model1 -- loss: 196.21\tbatch num: 24000/31161\n",
      "took 17.861862421035767 seconds\n",
      "Model2 -- loss: 203.07\tbatch num: 24000/31161\n",
      "took 17.861862421035767 seconds\n",
      "Model3 -- loss: 35082.38\tbatch num: 24000/31161\n",
      "took 17.861862421035767 seconds\n",
      "Model0 -- loss: 184.74\tbatch num: 25000/31161\n",
      "took 17.87465476989746 seconds\n",
      "Model1 -- loss: 189.65\tbatch num: 25000/31161\n",
      "took 17.87465476989746 seconds\n",
      "Model2 -- loss: 183.72\tbatch num: 25000/31161\n",
      "took 17.87465476989746 seconds\n",
      "Model3 -- loss: 38848.75\tbatch num: 25000/31161\n",
      "took 17.87465476989746 seconds\n",
      "Model0 -- loss: 242.23\tbatch num: 26000/31161\n",
      "took 17.88185954093933 seconds\n",
      "Model1 -- loss: 245.19\tbatch num: 26000/31161\n",
      "took 17.88185954093933 seconds\n",
      "Model2 -- loss: 247.14\tbatch num: 26000/31161\n",
      "took 17.88185954093933 seconds\n",
      "Model3 -- loss: 36515.87\tbatch num: 26000/31161\n",
      "took 17.88185954093933 seconds\n",
      "Model0 -- loss: 192.36\tbatch num: 27000/31161\n",
      "took 17.864500999450684 seconds\n",
      "Model1 -- loss: 182.49\tbatch num: 27000/31161\n",
      "took 17.864500999450684 seconds\n",
      "Model2 -- loss: 189.15\tbatch num: 27000/31161\n",
      "took 17.864500999450684 seconds\n",
      "Model3 -- loss: 35074.70\tbatch num: 27000/31161\n",
      "took 17.864500999450684 seconds\n",
      "Model0 -- loss: 293.15\tbatch num: 28000/31161\n",
      "took 17.8755784034729 seconds\n",
      "Model1 -- loss: 289.78\tbatch num: 28000/31161\n",
      "took 17.8755784034729 seconds\n",
      "Model2 -- loss: 285.99\tbatch num: 28000/31161\n",
      "took 17.8755784034729 seconds\n",
      "Model3 -- loss: 34872.49\tbatch num: 28000/31161\n",
      "took 17.8755784034729 seconds\n",
      "Model0 -- loss: 210.51\tbatch num: 29000/31161\n",
      "took 17.979369163513184 seconds\n",
      "Model1 -- loss: 215.75\tbatch num: 29000/31161\n",
      "took 17.979369163513184 seconds\n",
      "Model2 -- loss: 218.94\tbatch num: 29000/31161\n",
      "took 17.979369163513184 seconds\n",
      "Model3 -- loss: 37529.10\tbatch num: 29000/31161\n",
      "took 17.979369163513184 seconds\n",
      "Model0 -- loss: 188.60\tbatch num: 30000/31161\n",
      "took 18.112849473953247 seconds\n",
      "Model1 -- loss: 181.64\tbatch num: 30000/31161\n",
      "took 18.112849473953247 seconds\n",
      "Model2 -- loss: 192.37\tbatch num: 30000/31161\n",
      "took 18.112849473953247 seconds\n",
      "Model3 -- loss: 37317.69\tbatch num: 30000/31161\n",
      "took 18.112849473953247 seconds\n",
      "Model0 -- loss: 248.76\tbatch num: 31000/31161\n",
      "took 17.93981957435608 seconds\n",
      "Model1 -- loss: 244.76\tbatch num: 31000/31161\n",
      "took 17.93981957435608 seconds\n",
      "Model2 -- loss: 247.83\tbatch num: 31000/31161\n",
      "took 17.93981957435608 seconds\n",
      "Model3 -- loss: 36397.87\tbatch num: 31000/31161\n",
      "took 17.93981957435608 seconds\n",
      "Epoch 2 took 581.9791929721832 seconds\n",
      "model0 Test Set -- Average Loss: 35014.1923828125\n",
      "model1 Test Set -- Average Loss: 35014.1923828125\n",
      "model2 Test Set -- Average Loss: 35014.1923828125\n",
      "model3 Test Set -- Average Loss: 35014.1923828125\n",
      "Starting epoch 3\n",
      "Model0 -- loss: 194.36\tbatch num: 0/31161\n",
      "took 0.22999882698059082 seconds\n",
      "Model1 -- loss: 190.27\tbatch num: 0/31161\n",
      "took 0.22999882698059082 seconds\n",
      "Model2 -- loss: 196.63\tbatch num: 0/31161\n",
      "took 0.22999882698059082 seconds\n",
      "Model3 -- loss: 35009.66\tbatch num: 0/31161\n",
      "took 0.22999882698059082 seconds\n",
      "Model0 -- loss: 183.14\tbatch num: 1000/31161\n",
      "took 17.92647933959961 seconds\n",
      "Model1 -- loss: 181.27\tbatch num: 1000/31161\n",
      "took 17.927477836608887 seconds\n",
      "Model2 -- loss: 185.13\tbatch num: 1000/31161\n",
      "took 17.927477836608887 seconds\n",
      "Model3 -- loss: 36761.41\tbatch num: 1000/31161\n",
      "took 17.927477836608887 seconds\n",
      "Model0 -- loss: 249.31\tbatch num: 2000/31161\n",
      "took 17.852018356323242 seconds\n",
      "Model1 -- loss: 245.84\tbatch num: 2000/31161\n",
      "took 17.853018522262573 seconds\n",
      "Model2 -- loss: 249.17\tbatch num: 2000/31161\n",
      "took 17.853018522262573 seconds\n",
      "Model3 -- loss: 32767.89\tbatch num: 2000/31161\n",
      "took 17.853018522262573 seconds\n",
      "Model0 -- loss: 231.24\tbatch num: 3000/31161\n",
      "took 17.91948652267456 seconds\n",
      "Model1 -- loss: 220.64\tbatch num: 3000/31161\n",
      "took 17.91948652267456 seconds\n",
      "Model2 -- loss: 236.22\tbatch num: 3000/31161\n",
      "took 17.91948652267456 seconds\n",
      "Model3 -- loss: 33009.39\tbatch num: 3000/31161\n",
      "took 17.91948652267456 seconds\n",
      "Model0 -- loss: 192.39\tbatch num: 4000/31161\n",
      "took 17.895381450653076 seconds\n",
      "Model1 -- loss: 194.42\tbatch num: 4000/31161\n",
      "took 17.895381450653076 seconds\n",
      "Model2 -- loss: 194.62\tbatch num: 4000/31161\n",
      "took 17.89637565612793 seconds\n",
      "Model3 -- loss: 34071.79\tbatch num: 4000/31161\n",
      "took 17.89637565612793 seconds\n",
      "Model0 -- loss: 194.80\tbatch num: 5000/31161\n",
      "took 17.889801025390625 seconds\n",
      "Model1 -- loss: 189.50\tbatch num: 5000/31161\n",
      "took 17.889801025390625 seconds\n",
      "Model2 -- loss: 186.68\tbatch num: 5000/31161\n",
      "took 17.889801025390625 seconds\n",
      "Model3 -- loss: 35435.38\tbatch num: 5000/31161\n",
      "took 17.889801025390625 seconds\n",
      "Model0 -- loss: 199.03\tbatch num: 6000/31161\n",
      "took 17.940798044204712 seconds\n",
      "Model1 -- loss: 203.06\tbatch num: 6000/31161\n",
      "took 17.940798044204712 seconds\n",
      "Model2 -- loss: 198.77\tbatch num: 6000/31161\n",
      "took 17.940798044204712 seconds\n",
      "Model3 -- loss: 35023.62\tbatch num: 6000/31161\n",
      "took 17.940798044204712 seconds\n",
      "Model0 -- loss: 225.15\tbatch num: 7000/31161\n",
      "took 17.92816710472107 seconds\n",
      "Model1 -- loss: 224.43\tbatch num: 7000/31161\n",
      "took 17.92816710472107 seconds\n",
      "Model2 -- loss: 214.22\tbatch num: 7000/31161\n",
      "took 17.92816710472107 seconds\n",
      "Model3 -- loss: 34271.48\tbatch num: 7000/31161\n",
      "took 17.92816710472107 seconds\n",
      "Model0 -- loss: 248.34\tbatch num: 8000/31161\n",
      "took 17.93421769142151 seconds\n",
      "Model1 -- loss: 251.80\tbatch num: 8000/31161\n",
      "took 17.93421769142151 seconds\n",
      "Model2 -- loss: 249.29\tbatch num: 8000/31161\n",
      "took 17.93421769142151 seconds\n",
      "Model3 -- loss: 35042.41\tbatch num: 8000/31161\n",
      "took 17.93421769142151 seconds\n",
      "Model0 -- loss: 216.96\tbatch num: 9000/31161\n",
      "took 17.890875339508057 seconds\n",
      "Model1 -- loss: 215.70\tbatch num: 9000/31161\n",
      "took 17.890875339508057 seconds\n",
      "Model2 -- loss: 214.04\tbatch num: 9000/31161\n",
      "took 17.890875339508057 seconds\n",
      "Model3 -- loss: 35168.60\tbatch num: 9000/31161\n",
      "took 17.891873121261597 seconds\n",
      "Model0 -- loss: 216.94\tbatch num: 10000/31161\n",
      "took 17.90127944946289 seconds\n",
      "Model1 -- loss: 222.45\tbatch num: 10000/31161\n",
      "took 17.90127944946289 seconds\n",
      "Model2 -- loss: 219.13\tbatch num: 10000/31161\n",
      "took 17.90127944946289 seconds\n",
      "Model3 -- loss: 34942.21\tbatch num: 10000/31161\n",
      "took 17.90127944946289 seconds\n",
      "Model0 -- loss: 216.69\tbatch num: 11000/31161\n",
      "took 17.886661529541016 seconds\n",
      "Model1 -- loss: 214.85\tbatch num: 11000/31161\n",
      "took 17.886661529541016 seconds\n",
      "Model2 -- loss: 209.15\tbatch num: 11000/31161\n",
      "took 17.886661529541016 seconds\n",
      "Model3 -- loss: 34529.01\tbatch num: 11000/31161\n",
      "took 17.886661529541016 seconds\n",
      "Model0 -- loss: 175.41\tbatch num: 12000/31161\n",
      "took 17.965880632400513 seconds\n",
      "Model1 -- loss: 176.99\tbatch num: 12000/31161\n",
      "took 17.96687912940979 seconds\n",
      "Model2 -- loss: 172.51\tbatch num: 12000/31161\n",
      "took 17.96687912940979 seconds\n",
      "Model3 -- loss: 34574.90\tbatch num: 12000/31161\n",
      "took 17.96687912940979 seconds\n",
      "Model0 -- loss: 192.94\tbatch num: 13000/31161\n",
      "took 17.8566734790802 seconds\n",
      "Model1 -- loss: 191.09\tbatch num: 13000/31161\n",
      "took 17.8566734790802 seconds\n",
      "Model2 -- loss: 199.79\tbatch num: 13000/31161\n",
      "took 17.8566734790802 seconds\n",
      "Model3 -- loss: 35833.91\tbatch num: 13000/31161\n",
      "took 17.8566734790802 seconds\n",
      "Model0 -- loss: 192.55\tbatch num: 14000/31161\n",
      "took 18.876299142837524 seconds\n",
      "Model1 -- loss: 192.38\tbatch num: 14000/31161\n",
      "took 18.876299142837524 seconds\n",
      "Model2 -- loss: 184.83\tbatch num: 14000/31161\n",
      "took 18.876299142837524 seconds\n",
      "Model3 -- loss: 36401.47\tbatch num: 14000/31161\n",
      "took 18.876299142837524 seconds\n",
      "Model0 -- loss: 182.07\tbatch num: 15000/31161\n",
      "took 20.471999406814575 seconds\n",
      "Model1 -- loss: 185.60\tbatch num: 15000/31161\n",
      "took 20.471999406814575 seconds\n",
      "Model2 -- loss: 185.47\tbatch num: 15000/31161\n",
      "took 20.471999406814575 seconds\n",
      "Model3 -- loss: 36395.81\tbatch num: 15000/31161\n",
      "took 20.471999406814575 seconds\n",
      "Model0 -- loss: 192.87\tbatch num: 16000/31161\n",
      "took 18.491915941238403 seconds\n",
      "Model1 -- loss: 193.46\tbatch num: 16000/31161\n",
      "took 18.491915941238403 seconds\n",
      "Model2 -- loss: 186.54\tbatch num: 16000/31161\n",
      "took 18.491915941238403 seconds\n",
      "Model3 -- loss: 35328.94\tbatch num: 16000/31161\n",
      "took 18.491915941238403 seconds\n",
      "Model0 -- loss: 187.66\tbatch num: 17000/31161\n",
      "took 18.517635345458984 seconds\n",
      "Model1 -- loss: 185.23\tbatch num: 17000/31161\n",
      "took 18.517635345458984 seconds\n",
      "Model2 -- loss: 184.49\tbatch num: 17000/31161\n",
      "took 18.517635345458984 seconds\n",
      "Model3 -- loss: 32685.62\tbatch num: 17000/31161\n",
      "took 18.517635345458984 seconds\n",
      "Model0 -- loss: 224.48\tbatch num: 18000/31161\n",
      "took 18.622382402420044 seconds\n",
      "Model1 -- loss: 215.20\tbatch num: 18000/31161\n",
      "took 18.622382402420044 seconds\n",
      "Model2 -- loss: 214.84\tbatch num: 18000/31161\n",
      "took 18.622382402420044 seconds\n",
      "Model3 -- loss: 38705.05\tbatch num: 18000/31161\n",
      "took 18.622382402420044 seconds\n",
      "Model0 -- loss: 195.72\tbatch num: 19000/31161\n",
      "took 18.57503080368042 seconds\n",
      "Model1 -- loss: 188.83\tbatch num: 19000/31161\n",
      "took 18.57503080368042 seconds\n",
      "Model2 -- loss: 190.00\tbatch num: 19000/31161\n",
      "took 18.57503080368042 seconds\n",
      "Model3 -- loss: 34105.16\tbatch num: 19000/31161\n",
      "took 18.57503080368042 seconds\n",
      "Model0 -- loss: 218.40\tbatch num: 20000/31161\n",
      "took 18.1610209941864 seconds\n",
      "Model1 -- loss: 226.12\tbatch num: 20000/31161\n",
      "took 18.1610209941864 seconds\n",
      "Model2 -- loss: 224.48\tbatch num: 20000/31161\n",
      "took 18.1610209941864 seconds\n",
      "Model3 -- loss: 36006.55\tbatch num: 20000/31161\n",
      "took 18.1610209941864 seconds\n",
      "Model0 -- loss: 233.60\tbatch num: 21000/31161\n",
      "took 18.159430027008057 seconds\n",
      "Model1 -- loss: 237.80\tbatch num: 21000/31161\n",
      "took 18.159430027008057 seconds\n",
      "Model2 -- loss: 241.72\tbatch num: 21000/31161\n",
      "took 18.159430027008057 seconds\n",
      "Model3 -- loss: 35547.63\tbatch num: 21000/31161\n",
      "took 18.159430027008057 seconds\n",
      "Model0 -- loss: 233.36\tbatch num: 22000/31161\n",
      "took 18.543748378753662 seconds\n",
      "Model1 -- loss: 238.57\tbatch num: 22000/31161\n",
      "took 18.544749975204468 seconds\n",
      "Model2 -- loss: 228.52\tbatch num: 22000/31161\n",
      "took 18.544749975204468 seconds\n",
      "Model3 -- loss: 34087.92\tbatch num: 22000/31161\n",
      "took 18.544749975204468 seconds\n",
      "Model0 -- loss: 203.05\tbatch num: 23000/31161\n",
      "took 20.337862730026245 seconds\n",
      "Model1 -- loss: 210.82\tbatch num: 23000/31161\n",
      "took 20.337862730026245 seconds\n",
      "Model2 -- loss: 208.65\tbatch num: 23000/31161\n",
      "took 20.337862730026245 seconds\n",
      "Model3 -- loss: 34789.88\tbatch num: 23000/31161\n",
      "took 20.337862730026245 seconds\n",
      "Model0 -- loss: 254.13\tbatch num: 24000/31161\n",
      "took 20.453659534454346 seconds\n",
      "Model1 -- loss: 258.21\tbatch num: 24000/31161\n",
      "took 20.453659534454346 seconds\n",
      "Model2 -- loss: 248.34\tbatch num: 24000/31161\n",
      "took 20.453659534454346 seconds\n",
      "Model3 -- loss: 34138.89\tbatch num: 24000/31161\n",
      "took 20.453659534454346 seconds\n",
      "Model0 -- loss: 226.94\tbatch num: 25000/31161\n",
      "took 18.848259925842285 seconds\n",
      "Model1 -- loss: 231.30\tbatch num: 25000/31161\n",
      "took 18.849259853363037 seconds\n",
      "Model2 -- loss: 227.50\tbatch num: 25000/31161\n",
      "took 18.849259853363037 seconds\n",
      "Model3 -- loss: 32207.39\tbatch num: 25000/31161\n",
      "took 18.849259853363037 seconds\n",
      "Model0 -- loss: 158.04\tbatch num: 26000/31161\n",
      "took 18.199390411376953 seconds\n",
      "Model1 -- loss: 153.30\tbatch num: 26000/31161\n",
      "took 18.199390411376953 seconds\n",
      "Model2 -- loss: 160.71\tbatch num: 26000/31161\n",
      "took 18.199390411376953 seconds\n",
      "Model3 -- loss: 35001.20\tbatch num: 26000/31161\n",
      "took 18.20039129257202 seconds\n",
      "Model0 -- loss: 248.94\tbatch num: 27000/31161\n",
      "took 19.030333280563354 seconds\n",
      "Model1 -- loss: 239.18\tbatch num: 27000/31161\n",
      "took 19.030333280563354 seconds\n",
      "Model2 -- loss: 239.60\tbatch num: 27000/31161\n",
      "took 19.030333280563354 seconds\n",
      "Model3 -- loss: 34834.95\tbatch num: 27000/31161\n",
      "took 19.030333280563354 seconds\n",
      "Model0 -- loss: 268.16\tbatch num: 28000/31161\n",
      "took 19.64742350578308 seconds\n",
      "Model1 -- loss: 269.54\tbatch num: 28000/31161\n",
      "took 19.64742350578308 seconds\n",
      "Model2 -- loss: 272.01\tbatch num: 28000/31161\n",
      "took 19.64742350578308 seconds\n",
      "Model3 -- loss: 34376.50\tbatch num: 28000/31161\n",
      "took 19.64742350578308 seconds\n",
      "Model0 -- loss: 180.20\tbatch num: 29000/31161\n",
      "took 20.255302906036377 seconds\n",
      "Model1 -- loss: 176.03\tbatch num: 29000/31161\n",
      "took 20.255302906036377 seconds\n",
      "Model2 -- loss: 181.32\tbatch num: 29000/31161\n",
      "took 20.255302906036377 seconds\n",
      "Model3 -- loss: 37086.53\tbatch num: 29000/31161\n",
      "took 20.255302906036377 seconds\n",
      "Model0 -- loss: 205.18\tbatch num: 30000/31161\n",
      "took 19.31571888923645 seconds\n",
      "Model1 -- loss: 210.88\tbatch num: 30000/31161\n",
      "took 19.316720724105835 seconds\n",
      "Model2 -- loss: 213.00\tbatch num: 30000/31161\n",
      "took 19.316720724105835 seconds\n",
      "Model3 -- loss: 36403.64\tbatch num: 30000/31161\n",
      "took 19.316720724105835 seconds\n",
      "Model0 -- loss: 211.80\tbatch num: 31000/31161\n",
      "took 18.514177799224854 seconds\n",
      "Model1 -- loss: 221.10\tbatch num: 31000/31161\n",
      "took 18.514177799224854 seconds\n",
      "Model2 -- loss: 220.00\tbatch num: 31000/31161\n",
      "took 18.514177799224854 seconds\n",
      "Model3 -- loss: 38322.33\tbatch num: 31000/31161\n",
      "took 18.514177799224854 seconds\n",
      "Epoch 3 took 579.3680710792542 seconds\n",
      "model0 Test Set -- Average Loss: 35034.51220703125\n",
      "model1 Test Set -- Average Loss: 35034.51220703125\n",
      "model2 Test Set -- Average Loss: 35034.51220703125\n",
      "model3 Test Set -- Average Loss: 35034.51220703125\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "model0 = TestModel().cuda()\n",
    "optim0 = torch.optim.Adam(model0.parameters(), lr=0.001)\n",
    "lossfn0 = torch.nn.MSELoss().cuda()\n",
    "\n",
    "model1 = TestModel().cuda()\n",
    "optim1 = torch.optim.Adam(model1.parameters(), lr=0.0005)\n",
    "lossfn1 = torch.nn.MSELoss().cuda()\n",
    "\n",
    "model2 = TestModel().cuda()\n",
    "optim2 = torch.optim.Adam(model2.parameters(), lr=0.0001)\n",
    "lossfn2 = torch.nn.MSELoss().cuda()\n",
    "\n",
    "model3 = TestModel().cuda()\n",
    "optim3 = torch.optim.SGD(model3.parameters(), lr=0.001)\n",
    "lossfn3 = torch.nn.MSELoss().cuda()\n",
    "\n",
    "modelList = [model0, model1, model2, model3]\n",
    "optimList = [optim0, optim1, optim2, optim3]\n",
    "lossfnList = [lossfn0, lossfn1, lossfn2, lossfn3]\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    startTime = time.time()\n",
    "    print(f\"Starting epoch {t}\")\n",
    "    train_loop(trainDataLoader, modelList, lossfnList, optimList)\n",
    "    print(f\"Epoch {t} took {time.time() - startTime} seconds\")\n",
    "    test_loop(testDataLoader, modelList, lossfnList[0])\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c4049ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor(214.))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a091b56a-2d7b-49d4-8a47-e072039a3fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([207.7882], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0(testData[40][0].cuda())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
